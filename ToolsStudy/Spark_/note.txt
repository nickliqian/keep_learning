Spark用起来的确简单，但有一点特别要注意，你得按照Spark的范式写算法。

Spark是在数据集的层次上进行分布并行计算，是的，它只认成堆的数据

我们提交给Spark的计算任务，必须满足两个条件：
数据是可以分块的，每块构成一个集合。
算法只能在集合级别执行操作。