`scikit-learn==0.18 机器学习库`

#### 机器学习中的数据类型
- 离散型数据
- 连续型数据

#### 特征工程
特征工程即是数据转换，会影响模型的预测结果。
###### 1. 特征抽取
特征抽取针对非连续型数据。
```
字典特征抽取:
    DictVectorizer
文本特征抽取:
    CountVectorizer
    TfidfVectorizer
```
###### 2. 特征处理
通过特定的统计方法（数学方法）将数据转换成算法要求的数据。
```
数值型数据:
    1、归一化 MinMaxScaler
    2、标准化 StandardScaler
    3、缺失值 Imputer
类别型数据:
    one-hot编码
时间类型:
    时间的切分
```
###### 3. 特征选择
- 冗余：部分特征的相关度高，容易消耗计算性能
- 噪声：部分特征对预测结果有负影响
```
删除低方差特征
    VarianceThreshold
降维
    PCA
```
#### 解释
```
TF/IDF 代表词语重要程度
Term Frequency 词频
Inverse Document Frequency 逆文档频率
TF/IDF = log(词出现的总次数/当前文档出现次数)
```
#### 机器学习流程
```
原始数据
   ↓
特征工程 -> 特征值+目标值
   ↓
建立模型 -> 数据+算法
   ↓
模型评估 -> 通过则下一步，不通过则回到特征工程
   ↓
模型选择
   ↓
模型应用
```
#### 机器学习模型
定义：通过一种映射关系讲输入值到输出值
```
输入：学习特征值&目标值 + 被预测特征值
处理：模型
输出：预测输出值
```
#### 划分依据
1. 猫 or 狗 - 离散型数据 - 分类
2. 科技 or 体育 - 离散型数据 - 分类
3. 下个月票房数据 - 连续型数据 - 回归
4. 预测未来一段时间房价 - 连续型数据 - 回归
#### 机器学习算法分类
```
监督学习 - 特征值+目标值 - 分类，回归 - 输入特征有标签 - 有标准答案
无监督学习 - 特征值 - 聚类 - 输入特征无标签 - 无标准答案
```

#### KNN算法
分类模型评估： sklearn.metrics.classification_report
精确率precision与召回率recall

#### 朴素贝叶斯算法
算法
平滑系数
交叉验证与网格搜索

#### 决策树
信息熵
信息和消除不确定性是相关联的
特征A对训练数据集D的信息增益g(D,A)
定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差
公式：特征A信息增益 = 集合信息熵 - 条件A下信息条件熵
公式：g(D,A) = H(D) - H(D|A)
iD3: 信息增益 最大的准则
C4.5: 信息增益比 最大的准则
CART: 回归树 最小
      分类树 基尼系数 最小的准则
      
#### 随机森林


#### 线性回归
y = kx + b
b: 偏执
f(x) = w1x1 + w1x2 + ... + wdxd + b = wtx
b = w0*1
模型参数：w1 w2 w3 w4
T: 转置
误差
损失函数-衡量误差大小-最小二乘法
尽量去减小这个误差
寻找最小损失对应的w
最小二乘法之梯度下降
模型 + 策略 + 优化
回归性能评估：均方误差
