{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "csv_data=pd.read_csv(r'D:\\A\\data\\2019_xyk.csv')\n",
    "df1=csv_data.dropna(axis=1,how='all')   #删除全是空白值的数据\n",
    "\n",
    "df2=df1.dropna(thresh=0.7*len(df1),axis=1)   #剔除空白值在70%以上的的列\n",
    "\n",
    "df3=df2.fillna(df2.mean())    #按照每列的均值填充数据\n",
    "loan=df3\n",
    "\n",
    "loan['loan_status']=loan['loan_status'].replace(['Fully Paid','In Grace Period','Late (31-120 days)',\n",
    "                                                 'Late (16-30 days)','Charged Off','Default','Current'],\n",
    "                                               ['0','1','1','1','1','1','0'])\n",
    "loan=loan[loan['loan_status'].isin(['0','1'])]\n",
    "loan['loan_status']=loan['loan_status'].astype('int')\n",
    "\n",
    "loan['grade']=loan['grade'].replace(['A','B','C','D','E','F','G'],['5','4','3','2','1','0.5','0'])\n",
    "loan['emp_length']=loan['emp_length'].replace(['< 1 year','1 year','2 years','3 years','4 years','5 years',\n",
    "                                               '6 years','7 years','8 years','9 years','10+ years'],\n",
    "                                              ['0','1','2','3','4','5','6','7','8','9','10'])\n",
    "loan['home_ownership']=loan['home_ownership'].replace(['RENT','MORTGAGE','OWN','ANY'],['3','2','1','0'])\n",
    "loan['verification_status']=loan['verification_status'].replace(['Source Verified','Verified','Not Verified'],['3','2','1'])\n",
    "loan['term']=loan['term'].replace(['36 months','60 months'],['1','2'])\n",
    "oan=loan.drop(['issue_d'],axis=1)\n",
    "loan.iloc[0]\n",
    "loan=loan.drop(['purpose'],axis=1)\n",
    "loan=loan.drop(['addr_state'],axis=1)\n",
    "loan=loan.drop(['earliest_cr_line'],axis=1)\n",
    "loan['revol_util'] = loan['revol_util'].str.strip(\"%\").astype(float)/100\n",
    "loan['int_rate'] = loan['int_rate'].str.strip(\"%\").astype(float)/100\n",
    "loan=loan.drop(['application_type'],axis=1)\n",
    "loan['term']=loan['term'].replace([' 36 months',' 60 months'],['1','2'])\n",
    "\n",
    "loan['sub_grade']=loan['sub_grade'].replace(['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3','C4','C5',\n",
    "                                            'D1','D2','D3','D4','D5','E1','E2','E3','E4','E5','F1','F2','F3','F4','F5','G1','G2',\n",
    "                                            'G3','G4','G5'],['7','6.8','6.6','6.4','6.2','6','5.8','5.6','5.4','5.2','5','4.8','4.6','4.4','4.2',\n",
    "                                            '4','3.8','3.6','3.4','3.2','3','2.8','2.6','2.4','2.2','2','1.8','1.6','1.4','1.2','1','0.8',\n",
    "                                            '0.6','0.4','0.2'])\n",
    "loan=loan.drop(['emp_title'],axis=1)\n",
    "loan=loan.drop(['grade'],axis=1)\n",
    "loan=loan.drop(['issue_d'],axis=1)\n",
    "loan=loan.drop(['title'],axis=1)\n",
    "loan['pymnt_plan']=loan['pymnt_plan'].replace(['n','y'],['1','2'])\n",
    "loan=loan.drop(['zip_code'],axis=1)\n",
    "#loan=loan.drop(['next_pymnt_d'],axis=1)\n",
    "loan['initial_list_status']=loan['initial_list_status'].replace(['f','w'],['1','2'])\n",
    "loan=loan.drop(['last_pymnt_d'],axis=1)\n",
    "loan=loan.drop(['last_credit_pull_d'],axis=1)\n",
    "loan['hardship_flag']=loan['hardship_flag'].replace(['N','Y'],['1','2'])\n",
    "loan['disbursement_method']=loan['disbursement_method'].replace(['Cash','DirectPay'],['1','2'])\n",
    "loan['debt_settlement_flag']=loan['debt_settlement_flag'].replace(['N','Y'],['1','2'])\n",
    "loan=loan.fillna(loan.mode())    #以中位数数填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1beec0f3400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loan=loan.fillna(10)    ##不知道为啥我在用众数填充时，emp_length这一特征总是填不上，所以这个需要你自己先去看看这一列的众数是多少，\n",
    "                        #然后把10改成你的众数就好\n",
    "\n",
    "msno.matrix(loan) #这是一个查找空白值的程序，如果程序出来的结果都是一条条黑色的条，那就没问题，如果黑色的条纹中，有白色的横杠，那就是说有空白值\n",
    "                  #这个需要你先安装missingno的程序包，不想用直接把这两行删掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan=loan.drop([\"annual_inc\", \"delinq_2yrs\", \"revol_bal\", \"total_acc\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\", \"policy_code\"],axis=1)\n",
    "loan_1=loan.copy()\n",
    "\n",
    "\n",
    "data_1=loan_1[loan_1['loan_status'] == 1]\n",
    "data_0=loan_1[loan_1['loan_status'] == 0]\n",
    "\n",
    "data_1_train,data_1_test=train_test_split(data_1,test_size=.3,random_state=12)\n",
    "data_0_train,data_0_test=train_test_split(data_0,test_size=.3,random_state=12)\n",
    "train=pd.concat([data_1_train,data_0_train])\n",
    "test=pd.concat([data_1_test,data_0_test])\n",
    "\n",
    "train_X=train.drop(['loan_status'],axis=1)\n",
    "train_y=train['loan_status']\n",
    "test_X=test.drop(['loan_status'],axis=1)\n",
    "test_y=test['loan_status']\n",
    "\n",
    "#resampled_X,resampled_y=SMOTE(random_state=12).fit_sample(train_X,train_y)\n",
    "rf=RandomForestClassifier(n_estimators=500,max_depth=10,random_state=1).fit(train_X,train_y)\n",
    "importance=pd.DataFrame({'features':train_X.columns.values,'importance':rf.feature_importances_})\n",
    "importance.sort_values(by='importance',ascending=False).style.bar()\n",
    "loan=loan.drop(importance[importance['importance'] < 0.0015]['features'].values,axis=1)#此处的0.0015随你，改成多少都没问题，不过这\n",
    "                                                                                       #里尽可能小吧，毕竟还要在这里面做相关性，太大了特征太少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30132, 65) (12914, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyinstall\\virset\\virpy360set\\jup\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "d:\\pyinstall\\virset\\virpy360set\\jup\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-deb4b853cf80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m# 随机初始化神经网络的参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mw1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_units_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhidden_units_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mB1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhidden_units_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Variable'"
     ]
    }
   ],
   "source": [
    "def get_next_batch(i_count):\n",
    "    while True:\n",
    "        if i_count >= max_batch - 1:\n",
    "            i_count = int(i_count % max_batch)\n",
    "        a_x = test_X[i_count * batch_size:(i_count + 1) * batch_size]\n",
    "        if a_x.shape[0] != 100:\n",
    "            i_count += 1\n",
    "            continue\n",
    "        a_y = train_y[i_count * batch_size:(i_count + 1) * batch_size]\n",
    "        return a_x, a_y\n",
    "\n",
    "\n",
    "def get_next_batch_test():\n",
    "    a_x = train_X[0:100]\n",
    "    a_y = test_y[0:100]\n",
    "    return a_x, a_y\n",
    "\n",
    "\n",
    "def mmscaler(data):\n",
    "    # feature_range 映射到指定范围\n",
    "    maxmin = MinMaxScaler(feature_range=[0,1])\n",
    "    data = maxmin.fit_transform(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "df = loan\n",
    "# 分割数据\n",
    "train, test = train_test_split(df, test_size=.3, random_state=12)\n",
    "print(train.shape, test.shape)\n",
    "train_X = train.drop('loan_status', axis=1)\n",
    "train_X = mmscaler(train_X)  # 归一化\n",
    "\n",
    "train_y = np.zeros([train_X.shape[0], 2])\n",
    "for index, value in enumerate(train['loan_status']):\n",
    "    if value == 0:\n",
    "        train_y[index, :] = [1, 0]\n",
    "    elif value == 1:\n",
    "        train_y[index, :] = [0, 1]\n",
    "train_y = pd.DataFrame(train_y)\n",
    "\n",
    "test_X = test.drop('loan_status', axis=1)\n",
    "test_X = mmscaler(test_X)\n",
    "test_y = np.zeros([test_X.shape[0], 2])\n",
    "for index, value in enumerate(test['loan_status']):\n",
    "    if value == 0:\n",
    "        test_y[index, :] = [1, 0]\n",
    "    elif value == 1:\n",
    "        test_y[index, :] = [0, 1]\n",
    "test_y = pd.DataFrame(test_y)\n",
    "\n",
    "num_classes = 2  # 输出大小\n",
    "input_size = 65  # 输入大小\n",
    "hidden_units_size = 30  # 隐藏层节点数量\n",
    "batch_size = 100\n",
    "\n",
    "rows_number = train_X.shape[0]\n",
    "max_batch = int(rows_number / batch_size)\n",
    "\n",
    "# 随机初始化神经网络的参数\n",
    "w1 = tf.Variable(tf.random_normal([input_size, hidden_units_size], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([hidden_units_size, num_classes], stddev=1, seed=1))\n",
    "B1 = tf.Variable(tf.constant(0.1), [hidden_units_size])\n",
    "B2 = tf.Variable(tf.constant(0.1), [num_classes])\n",
    "\n",
    "# 在shape的一个维度上使用None可以方便使用不同的batch大小。\n",
    "x = tf.placeholder(tf.float32, shape=(None, input_size), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, num_classes), name='y-input')\n",
    "\n",
    "# 定义计算图\n",
    "a = tf.matmul(x, w1) + B1\n",
    "a_r = tf.nn.relu(a)\n",
    "y = tf.matmul(a_r, w2) + B2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y))  # 定义交叉熵损失函数\n",
    "train_step = tf.train.AdadeltaOptimizer(0.001).minimize(cross_entropy)  # 定义优化方法为Ada并最小号cross_entropy\n",
    "\n",
    "# 计算准确率\n",
    "origin_y = tf.argmax(y_, axis=1)\n",
    "predict_y = tf.argmax(y, axis=1)\n",
    "\n",
    "correct_prediction = tf.equal(origin_y, predict_y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 创建一个Session用来执行图\n",
    "with tf.Session() as sess:\n",
    "    # 初始化所有的变量\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    STEPS = 10000\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    if os.path.exists(\"model/\"):\n",
    "        try:\n",
    "            saver.restore(sess, \"model/\")\n",
    "        # 判断捕获model文件夹中没有模型文件的错误\n",
    "        except ValueError:\n",
    "            print(\"model文件夹为空，将创建新模型\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for i in range(STEPS):\n",
    "        # 每次选择batch_size个样本进行训练\n",
    "        start = (i * batch_size) % rows_number\n",
    "        end = min(start + batch_size, rows_number)\n",
    "        # 通过选取的样本训练神经网络并更新参数\n",
    "        _, total_cross_entropy, accuracy_new = sess.run([train_step, cross_entropy, accuracy], feed_dict={x: train_X[start:end], y_: train_y[start:end]})\n",
    "        # 每1000次输出损失函数的结果\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loop: {}, loss: {}, acc_train: {}\".format(i, total_cross_entropy, accuracy_new))\n",
    "        if i % 5000 == 0:\n",
    "            saver.save(sess, \"model/\")\n",
    "        accuracy_test = sess.run(accuracy, feed_dict={x: test_X, y_: test_y})\n",
    "    print(\"accuracy_test\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
