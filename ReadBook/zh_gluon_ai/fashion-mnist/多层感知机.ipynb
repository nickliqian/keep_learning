{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:27:48.598975Z",
     "start_time": "2020-02-27T16:27:48.590444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n",
      "0.4.2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import d2lzh1981 as d2l\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:08:40.650917Z",
     "start_time": "2020-02-27T16:08:40.564396Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root='/Users/nick/Documents/dataset/FashionMNIST2065', train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='/Users/nick/Documents/dataset/FashionMNIST2065', train=False, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:29:35.597061Z",
     "start_time": "2020-02-27T16:29:35.591511Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "if sys.platform.startswith('win'):\n",
    "    num_workers = 0\n",
    "else:\n",
    "    num_workers = 4\n",
    "    \n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:28:40.777205Z",
     "start_time": "2020-02-27T16:28:40.748987Z"
    }
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:27:22.479860Z",
     "start_time": "2020-02-27T16:27:22.467845Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "    \n",
    "net = nn.Sequential(\n",
    "        FlattenLayer(),\n",
    "        nn.Linear(num_inputs, num_hiddens),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens, num_outputs), \n",
    "        )\n",
    "    \n",
    "for params in net.parameters():\n",
    "    nn.init.normal_(params, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:27:24.298549Z",
     "start_time": "2020-02-27T16:27:24.295474Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:30:08.866824Z",
     "start_time": "2020-02-27T16:29:48.016460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 281.09it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0039, train acc 0.855, test acc 0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 289.78it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.0035, train acc 0.869, test acc 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 261.83it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.0033, train acc 0.877, test acc 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 270.33it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 0.0031, train acc 0.884, test acc 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 274.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 0.0030, train acc 0.889, test acc 0.894\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "    for X, y in tqdm(train_iter):\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y).sum()\n",
    "\n",
    "        # 梯度清零\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        elif params is not None and params[0].grad is not None:\n",
    "            for param in params:\n",
    "                param.grad.data.zero_()\n",
    "\n",
    "        l.backward()\n",
    "        if optimizer is None:\n",
    "            sgd(params, lr, batch_size)\n",
    "        else:\n",
    "            optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
    "\n",
    "\n",
    "        train_l_sum += l.item()\n",
    "        train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "        n += y.shape[0]\n",
    "    test_acc = evaluate_accuracy(test_iter, net)\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "          % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T16:33:27.145601Z",
     "start_time": "2020-02-27T16:33:27.008413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
       "        2, 3, 0, 2, 4, 4, 5, 3, 4, 6, 0, 8, 5, 2, 1, 6, 6, 7, 9, 5, 9, 2, 7, 3,\n",
       "        0, 3, 3, 3, 7, 2, 2, 0, 0, 8, 3, 3, 5, 6, 5, 5, 0, 2, 0, 0, 4, 1, 0, 1,\n",
       "        6, 3, 1, 4, 4, 6, 1, 5, 1, 3, 5, 7, 9, 7, 1, 7, 9, 7, 7, 3, 2, 9, 3, 6,\n",
       "        6, 1, 1, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, y in test_iter:\n",
    "    s = net(X).argmax(dim=1)\n",
    "    break\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
