{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:13.906979Z",
     "start_time": "2020-02-20T15:53:12.665759Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Imputer, LabelBinarizer, Normalizer, OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:13.931228Z",
     "start_time": "2020-02-20T15:53:13.908631Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_feature(df, key, target, aggs):   \n",
    "    \"\"\"\n",
    "    输出不同聚合字段-方法组合dataframe\n",
    "    df 数据表\n",
    "    key 用于分组的字段  x, y, v, d\n",
    "    target 用于计算聚合的字段\n",
    "    aggs  聚合的方法  ['max','min','mean','std','skew','sum']\n",
    "    \"\"\"\n",
    "    agg_dict = {}\n",
    "    for ag in aggs:\n",
    "        agg_dict[f'{target}_{ag}'] = ag  # 例如 x_max 代表输出每个船（id）数据中里面的最大值\n",
    "#     print(agg_dict)\n",
    "    t = df.groupby(key)[target].agg(agg_dict).reset_index()\n",
    "#     print(t)\n",
    "    return t\n",
    "\n",
    "def extract_feature(df, train):\n",
    "    # x的最大值，最小值，平均值，标准差，峰度，加和\n",
    "    t = group_feature(df, 'ship','x',['max','min','mean','std','skew','sum', 'median'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # x的数量\n",
    "    t = group_feature(df, 'ship','x',['count'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # y的最大值，最小值，平均值，标准差，峰度，加和\n",
    "    t = group_feature(df, 'ship','y',['max','min','mean','std','skew','sum', 'median'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "#     # speed_time 的最大值，最小值，平均值，标准差，峰度，加和\n",
    "#     t = group_feature(df, 'ship','speed_time',['max','min','mean','std','skew','sum', 'median'])\n",
    "#     train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # xy 的最大值，最小值，平均值，标准差，峰度，加和\n",
    "    t = group_feature(df, 'ship','xy',['max','min','mean','std','skew','sum', 'median'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "#     # xy_loc_pca 的最大值，最小值，平均值，标准差，峰度，加和\n",
    "#     t = group_feature(df, 'ship','xy_loc_pca',['max','min','mean','std','skew','sum', 'median'])\n",
    "#     train = pd.merge(train, t, on='ship', how='left')    \n",
    "    \n",
    "#     # vd的最大值，最小值，平均值，标准差，峰度，加和\n",
    "#     t = group_feature(df, 'ship','vd',['max','min','mean','std','skew','sum'])\n",
    "#     train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # 速度的最大值，最小值，平均值，标准差，峰度，加和\n",
    "    t = group_feature(df, 'ship','v',['max','min','mean','std','skew','sum', 'median'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # 方向的最大值，最小值，平均值，标准差，峰度，加和\n",
    "    t = group_feature(df, 'ship','d',['max','min','mean','std','skew','sum', 'median'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # x y 的最大值和最小值的交叉相减\n",
    "    train['x_max_x_min'] = train['x_max'] - train['x_min']\n",
    "    train['y_max_y_min'] = train['y_max'] - train['y_min']\n",
    "    train['y_max_x_min'] = train['y_max'] - train['x_min']\n",
    "    train['x_max_y_min'] = train['x_max'] - train['y_min']\n",
    "    \n",
    "    train['x_median_a_y_median'] = train[\"x_median\"] + train[\"y_median\"]\n",
    "    train['x_median_b_y_median'] = train[\"x_median\"] - train[\"y_median\"]\n",
    "    train['x_median_c_y_median'] = train[\"x_median\"] * train[\"y_median\"]\n",
    "    train['x_median_d_y_median'] = train[\"x_median\"] / np.where(train['y_median']==0, 0.001, train['y_median'])\n",
    "    \n",
    "    bizhi = [\"x\", \"y\", \"v\", \"d\"]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if i < j:\n",
    "                n = \"{}_d_{}\".format(bizhi[i], bizhi[j])\n",
    "                train[n] = train[bizhi[i]] / np.where(train[bizhi[j]]==0, 0.001, train[bizhi[j]])\n",
    "    \n",
    "    # slope 第一个值： y的最大值和最小值的差\n",
    "    # slope 第二个值： x的最大值最小值的差，如果差值为0，则去极小值 0.001\n",
    "    # slope代表x y 极差的比值，可以理解为斜度，坡度\n",
    "    # np.where 是条件判断 True -> x;False -> y;\n",
    "    train['slope'] = train['y_max_y_min'] / np.where(train['x_max_x_min']==0, 0.001, train['x_max_x_min'])\n",
    "    # x y 的极差相乘，表示该船的最大活动面积\n",
    "    train['area'] = train['x_max_x_min'] * train['y_max_y_min']\n",
    "    \n",
    "    # 每条船数据中出现小时值次数最多的值\n",
    "    mode_hour = df.groupby('ship')['hour'].agg(lambda x:x.value_counts().index[0]).to_dict()\n",
    "    train['mode_hour'] = train['ship'].map(mode_hour)\n",
    "    \n",
    "    # 小时的最大值，最小值\n",
    "    t = group_feature(df, 'ship','hour',['max','min'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    # 一次任务涉及到的小时数值\n",
    "    hour_nunique = df.groupby('ship')['hour'].nunique().to_dict()\n",
    "    # 一次任务涉及的天数\n",
    "    date_nunique = df.groupby('ship')['date'].nunique().to_dict()\n",
    "    train['hour_nunique'] = train['ship'].map(hour_nunique)\n",
    "    train['date_nunique'] = train['ship'].map(date_nunique)\n",
    "    \n",
    "    # 一次任务的时间差\n",
    "    t = df.groupby('ship')['time'].agg({'diff_time':lambda x:np.max(x)-np.min(x)}).reset_index()\n",
    "    # 时间差的天数，秒数\n",
    "    t['diff_day'] = t['diff_time'].dt.days\n",
    "    t['diff_second'] = t['diff_time'].dt.seconds\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    return train\n",
    "\n",
    "def extract_dt(df):\n",
    "    # 时间格式转换\n",
    "#     df['time'] = pd.to_datetime(df['time'], format='%m%d %H:%M:%S')\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # df['month'] = df['time'].dt.month\n",
    "    # df['day'] = df['time'].dt.day\n",
    "    df['date'] = df['time'].dt.date  # 提取日期\n",
    "    df['hour'] = df['time'].dt.hour  # 提取小时\n",
    "    # df = df.drop_duplicates(['ship','month'])\n",
    "    df['weekday'] = df['time'].dt.weekday  # 提取星期\n",
    "    return df\n",
    "\n",
    "def PAC():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:19.653213Z",
     "start_time": "2020-02-20T15:53:13.933767Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据，整理列信息\n",
    "# train = pd.read_hdf('../input/train.h5')\n",
    "train = pd.read_csv(\"/Users/nick/Documents/dataset/智慧海洋/train_v2.csv\")\n",
    "train = train.drop([\"Unnamed: 0\"], axis=1)\n",
    "train = train.rename(columns={\n",
    "    \"速度\": \"v\",\n",
    "    \"方向\": \"d\",\n",
    "    \"渔船ID\": \"ship\",\n",
    "})\n",
    "# train = df.drop_duplicates(['ship','type'])\n",
    "train = train.sort_values(\"ship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:20.977445Z",
     "start_time": "2020-02-20T15:53:19.655522Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据，整理列信息\n",
    "# test = pd.read_hdf('../input/test.h5')\n",
    "test = pd.read_csv(\"/Users/nick/Documents/dataset/智慧海洋/test_v2.csv\")\n",
    "\n",
    "test = test.drop([\"Unnamed: 0\"], axis=1)\n",
    "test = test.rename(columns={\n",
    "    \"速度\": \"v\",\n",
    "    \"方向\": \"d\",\n",
    "    \"渔船ID\": \"ship\",\n",
    "})\n",
    "test = test.sort_values(\"ship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.226335Z",
     "start_time": "2020-02-20T15:53:20.979641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>record</th>\n",
       "      <th>ship</th>\n",
       "      <th>speed_time</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>v</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399657</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1900-11-09 16:18:22</td>\n",
       "      <td>拖网</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>5.130672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399676</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1900-11-09 13:08:23</td>\n",
       "      <td>拖网</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>5.130672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399677</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1900-11-09 12:58:23</td>\n",
       "      <td>拖网</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>5.130672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399678</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1900-11-09 12:48:23</td>\n",
       "      <td>拖网</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>5.130672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399679</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1900-11-09 12:38:22</td>\n",
       "      <td>拖网</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>5.130672e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        d record  ship  speed_time                 time type    v  \\\n",
       "399657  0  train     0       600.0  1900-11-09 16:18:22   拖网  0.0   \n",
       "399676  0  train     0       600.0  1900-11-09 13:08:23   拖网  0.0   \n",
       "399677  0  train     0       600.0  1900-11-09 12:58:23   拖网  0.0   \n",
       "399678  0  train     0       600.0  1900-11-09 12:48:23   拖网  0.0   \n",
       "399679  0  train     0       601.0  1900-11-09 12:38:22   拖网  0.0   \n",
       "\n",
       "                   x             y  \n",
       "399657  6.118352e+06  5.130672e+06  \n",
       "399676  6.118352e+06  5.130672e+06  \n",
       "399677  6.118352e+06  5.130672e+06  \n",
       "399678  6.118352e+06  5.130672e+06  \n",
       "399679  6.118352e+06  5.130672e+06  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并训练集和测试集\n",
    "train = train[:10000]\n",
    "test = test[:5000]\n",
    "\n",
    "train[\"record\"] = \"train\"\n",
    "test[\"record\"] = \"test\"\n",
    "df_all = pd.concat([train, test], axis=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.266882Z",
     "start_time": "2020-02-20T15:53:21.228185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>ship</th>\n",
       "      <th>speed_time</th>\n",
       "      <th>v</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>14962.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>119.754933</td>\n",
       "      <td>2343.803400</td>\n",
       "      <td>661.591632</td>\n",
       "      <td>1.743463</td>\n",
       "      <td>6.342667e+06</td>\n",
       "      <td>5.325664e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.750804</td>\n",
       "      <td>3296.560713</td>\n",
       "      <td>313.853556</td>\n",
       "      <td>2.697080</td>\n",
       "      <td>3.762511e+05</td>\n",
       "      <td>2.991422e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.228590e+06</td>\n",
       "      <td>4.577467e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>6.182402e+06</td>\n",
       "      <td>5.163718e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>6.262057e+06</td>\n",
       "      <td>5.242462e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>221.000000</td>\n",
       "      <td>7003.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>6.510065e+06</td>\n",
       "      <td>5.503023e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>360.000000</td>\n",
       "      <td>7012.000000</td>\n",
       "      <td>9118.000000</td>\n",
       "      <td>80.730000</td>\n",
       "      <td>7.119130e+06</td>\n",
       "      <td>6.136033e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  d          ship    speed_time             v             x  \\\n",
       "count  15000.000000  15000.000000  14962.000000  15000.000000  1.500000e+04   \n",
       "mean     119.754933   2343.803400    661.591632      1.743463  6.342667e+06   \n",
       "std      115.750804   3296.560713    313.853556      2.697080  3.762511e+05   \n",
       "min        0.000000      0.000000      1.000000      0.000000  5.228590e+06   \n",
       "25%        0.000000     10.000000    599.000000      0.110000  6.182402e+06   \n",
       "50%       91.000000     19.000000    600.000000      0.320000  6.262057e+06   \n",
       "75%      221.000000   7003.000000    603.000000      3.020000  6.510065e+06   \n",
       "max      360.000000   7012.000000   9118.000000     80.730000  7.119130e+06   \n",
       "\n",
       "                  y  \n",
       "count  1.500000e+04  \n",
       "mean   5.325664e+06  \n",
       "std    2.991422e+05  \n",
       "min    4.577467e+06  \n",
       "25%    5.163718e+06  \n",
       "50%    5.242462e+06  \n",
       "75%    5.503023e+06  \n",
       "max    6.136033e+06  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据的相关统计指标\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对xy的高频坐标点进行one-hot变量的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.362981Z",
     "start_time": "2020-02-20T15:53:21.269052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_xy_count (15000, 3)\n",
      "df_all_xy_count (6623, 3)\n",
      "x_count_dict: 0\n",
      "y_count_dict: 0\n"
     ]
    }
   ],
   "source": [
    "# x y 值统计特征\n",
    "df_all_xy_count = df_all[[\"ship\", \"x\", \"y\"]]\n",
    "\n",
    "print(\"df_all_xy_count\", df_all_xy_count.shape)\n",
    "# 删掉 ship-x-y 的重复值\n",
    "\n",
    "df_all_xy_count[\"x\"] = (df_all_xy_count[\"x\"]/10).astype(int)\n",
    "df_all_xy_count[\"y\"] = (df_all_xy_count[\"y\"]/10).astype(int)\n",
    "\n",
    "df_all_xy_count = df_all_xy_count.drop_duplicates([\"ship\", \"x\", \"y\"])\n",
    "print(\"df_all_xy_count\", df_all_xy_count.shape)\n",
    "\n",
    "# df_all_xy_count[\"ship\"] = df_all_xy_count.astype(\"object\")\n",
    "# df_all_xy_count[\"x\"] = df_all_xy_count.astype(\"object\")\n",
    "# df_all_xy_count[\"y\"] = df_all_xy_count.astype(\"object\")\n",
    "\n",
    "x_counts = df_all_xy_count.groupby(\"x\")[\"x\"].count()\n",
    "x_count_dict = x_counts[x_counts >= 30].to_dict()\n",
    "\n",
    "y_counts = df_all_xy_count.groupby(\"y\")[\"y\"].count()\n",
    "y_count_dict = y_counts[y_counts >= 30].to_dict()\n",
    "\n",
    "# x_count_dict\n",
    "# y_count_dict\n",
    "\n",
    "print(\"x_count_dict: {}\".format(len(x_count_dict)))\n",
    "print(\"y_count_dict: {}\".format(len(y_count_dict)))\n",
    "\n",
    "# 查看xy的交叉值\n",
    "# print(set(x_count_dict) & set(y_count_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.373704Z",
     "start_time": "2020-02-20T15:53:21.366838Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ship\n",
       "0       414\n",
       "1       385\n",
       "2       233\n",
       "3       335\n",
       "4       401\n",
       "5       375\n",
       "6       394\n",
       "7       348\n",
       "8       366\n",
       "9       397\n",
       "10      397\n",
       "11      377\n",
       "12      416\n",
       "13      426\n",
       "14      402\n",
       "15      382\n",
       "16      398\n",
       "17      265\n",
       "18      409\n",
       "19      388\n",
       "20      376\n",
       "21      415\n",
       "22      422\n",
       "23      399\n",
       "24      392\n",
       "25      388\n",
       "26      100\n",
       "7000    373\n",
       "7001    458\n",
       "7002    410\n",
       "7003    425\n",
       "7004    398\n",
       "7005    404\n",
       "7006    316\n",
       "7007    411\n",
       "7008    430\n",
       "7009    419\n",
       "7010    412\n",
       "7011    398\n",
       "7012    146\n",
       "Name: ship, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 船号\n",
    "df_all.groupby(\"ship\")[\"ship\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.382099Z",
     "start_time": "2020-02-20T15:53:21.376906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 7000, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012]\n"
     ]
    }
   ],
   "source": [
    "ship_index_list = list(df_all.groupby(\"ship\")[\"ship\"].count().index)\n",
    "print(ship_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.445315Z",
     "start_time": "2020-02-20T15:53:21.384944Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 726.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# 整理每一条船的 x => [] 和 y => [] 还有对应的船号\n",
    "x_count_list = []\n",
    "y_count_list = []\n",
    "ship_list = []\n",
    "for i in tqdm(ship_index_list):\n",
    "    ship_list.append(i)\n",
    "    x_count_list.append(list(df_all_xy_count[df_all_xy_count[\"ship\"]==i][\"x\"]))\n",
    "    y_count_list.append(list(df_all_xy_count[df_all_xy_count[\"ship\"]==i][\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.461490Z",
     "start_time": "2020-02-20T15:53:21.447116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship</th>\n",
       "      <th>x_count_list</th>\n",
       "      <th>y_count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[611835, 615203, 615122, 615042, 614961, 61488...</td>\n",
       "      <td>[513067, 512487, 512521, 512556, 512590, 51262...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ship                                       x_count_list  \\\n",
       "0     0  [611835, 615203, 615122, 615042, 614961, 61488...   \n",
       "\n",
       "                                        y_count_list  \n",
       "0  [513067, 512487, 512521, 512556, 512590, 51262...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ship 对应 x‘ y’ 的 df\n",
    "xy_count_list = pd.DataFrame({\"ship\": ship_list, \"x_count_list\": x_count_list, \"y_count_list\": y_count_list})\n",
    "\n",
    "# 补充one hot编码的列， 全部填充0\n",
    "for a, _ in tqdm(x_count_dict.items()):\n",
    "    a = \"{}_x\".format(a)\n",
    "    xy_count_list[a] = 0\n",
    "    \n",
    "for a, _ in tqdm(y_count_dict.items()):\n",
    "    a = \"{}_y\".format(a)\n",
    "    xy_count_list[a] = 0\n",
    "    \n",
    "xy_count_list.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.507305Z",
     "start_time": "2020-02-20T15:53:21.463592Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 2179.00it/s]\n",
      "40it [00:00, 2671.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 填充每个船只的one hot编码 对应的值\n",
    "print(xy_count_list.shape)\n",
    "# xy_count_list = xy_count_list.reset_index(drop=True)\n",
    "\n",
    "for index2, i_list in tqdm(enumerate(xy_count_list[\"x_count_list\"])):\n",
    "    \n",
    "    common_key = set(list(x_count_dict.keys())) & set(i_list)\n",
    "    common_key = list(common_key)\n",
    "    \n",
    "    common_key_s = []\n",
    "    for c in common_key:\n",
    "        common_key_s.append(\"{}_x\".format(c))\n",
    "    \n",
    "    try:\n",
    "        xy_count_list.loc[index2, common_key_s] = 1\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "for index2, i_list in tqdm(enumerate(xy_count_list[\"y_count_list\"])):\n",
    "    \n",
    "    common_key = set(list(y_count_dict.keys())) & set(i_list)\n",
    "    common_key = list(common_key)\n",
    "    \n",
    "    common_key_s = []\n",
    "    for c in common_key:\n",
    "        common_key_s.append(\"{}_y\".format(c))\n",
    "    \n",
    "    try:\n",
    "        xy_count_list.loc[index2, common_key_s] = 1\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.518720Z",
     "start_time": "2020-02-20T15:53:21.509300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship</th>\n",
       "      <th>x_count_list</th>\n",
       "      <th>y_count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[611835, 615203, 615122, 615042, 614961, 61488...</td>\n",
       "      <td>[513067, 512487, 512521, 512556, 512590, 51262...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ship                                       x_count_list  \\\n",
       "0     0  [611835, 615203, 615122, 615042, 614961, 61488...   \n",
       "\n",
       "                                        y_count_list  \n",
       "0  [513067, 512487, 512521, 512556, 512590, 51262...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_count_list.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:58:18.525821Z",
     "start_time": "2020-02-20T15:58:18.514140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除不用的列\n",
    "xy_count_list_drop_df_ship = xy_count_list[[\"ship\"]]\n",
    "xy_count_list_drop_df = xy_count_list.drop([\"ship\", \"x_count_list\", \"y_count_list\"], axis=1)\n",
    "xy_count_list_drop_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.677198Z",
     "start_time": "2020-02-20T15:53:21.529457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(40, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8e27e0dd794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_count_list_drop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreduced_xy_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_count_list_drop_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_xy_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/ML-training/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \"\"\"\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/ML-training/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'barnes_hut'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             X = check_array(X, ensure_min_samples=2,\n\u001b[0;32m--> 700\u001b[0;31m                             dtype=[np.float32, np.float64])\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\n",
      "\u001b[0;32m~/.venv/ML-training/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    556\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                              % (n_features, array.shape, ensure_min_features,\n\u001b[0;32m--> 558\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(40, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# 对较高频的坐标进行降维\n",
    "print(xy_count_list_drop_df.shape)\n",
    "pca = TSNE(n_components=3)\n",
    "reduced_xy_count = pca.fit_transform(xy_count_list_drop_df)\n",
    "print(reduced_xy_count.shape)\n",
    "\n",
    "reduced_xy_count_df = pd.DataFrame(reduced_xy_count)\n",
    "reduced_xy_count_df[\"ship\"] = xy_count_list_drop_df_ship[\"ship\"].values\n",
    "reduced_xy_count_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对坐标划分网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.680987Z",
     "start_time": "2020-02-20T15:53:12.793Z"
    }
   },
   "outputs": [],
   "source": [
    "# 确定xy网格范围\n",
    "xmin = df_all[\"x\"].min()\n",
    "xmax = df_all[\"x\"].max()\n",
    "\n",
    "ymin = df_all[\"y\"].min()\n",
    "ymax = df_all[\"y\"].max()\n",
    "\n",
    "x_offset = xmax - xmin\n",
    "y_offset = ymax - ymin\n",
    "\n",
    "offset_count = 30\n",
    "\n",
    "x_box = x_offset / offset_count\n",
    "y_box = y_offset / offset_count\n",
    "\n",
    "\n",
    "print(\"x min: {}\".format(xmin))\n",
    "print(\"x max: {}\".format(xmax))\n",
    "print(\"x offset: {}\".format(x_offset))\n",
    "print(\"x box: {}\".format(x_box))\n",
    "\n",
    "print(\"y min: {}\".format(ymin))\n",
    "print(\"y max: {}\".format(ymax))\n",
    "print(\"y offset: {}\".format(y_offset))\n",
    "print(\"y box: {}\".format(y_box))\n",
    "\n",
    "# 计算网格区域\n",
    "x_list = []\n",
    "for i in range(offset_count + 1):\n",
    "    x_list.append(xmin + i * x_box)\n",
    "    \n",
    "y_list = []\n",
    "for i in range(offset_count + 1):\n",
    "    y_list.append(ymin + i * y_box)\n",
    "    \n",
    "pd.DataFrame({\"x_area\": x_list, \"y_area\": y_list})[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.682593Z",
     "start_time": "2020-02-20T15:53:12.797Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对网格编码后赋值\n",
    "def map_loc_x(x):\n",
    "    for i in range(offset_count+1):\n",
    "        if x <= x_list[i]:\n",
    "            return i\n",
    "        if x > x_list[i] and x <= x_list[i+1]:\n",
    "            return i\n",
    "\n",
    "def map_loc_y(y):\n",
    "    for i in range(offset_count+1):\n",
    "        if y <= y_list[i]:\n",
    "            return i\n",
    "        if y > y_list[i] and y <= y_list[i+1]:\n",
    "            return i\n",
    "        \n",
    "df_all[\"x_loc\"] = df_all[\"x\"].apply(map_loc_x)\n",
    "df_all[\"y_loc\"] = df_all[\"y\"].apply(map_loc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.684028Z",
     "start_time": "2020-02-20T15:53:12.800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all[df_all[\"ship\"]==0][[\"x_loc\", \"y_loc\"]].plot.scatter(x='x_loc', y='y_loc', figsize=(6,5))\n",
    "plt.show()\n",
    "df_all[df_all[\"ship\"]==0][[\"x\", \"y\"]].plot.scatter(x='x', y='y', figsize=(6,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.685102Z",
     "start_time": "2020-02-20T15:53:12.804Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造新列代表每一个区域\n",
    "df_all[\"x_y_loc_area\"] = df_all['x_loc'].astype(str) + ',' + df_all['y_loc'].astype(str)\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.686649Z",
     "start_time": "2020-02-20T15:53:12.835Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 抽取每一个区域和对应ship\n",
    "df_xyloc = df_all[[\"x_y_loc_area\"]]\n",
    "\n",
    "df_xyloc_dummies = pd.get_dummies(df_xyloc)\n",
    "print(df_xyloc_dummies.shape)\n",
    "df_xyloc_dummies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.688026Z",
     "start_time": "2020-02-20T15:53:12.840Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_xyloc_dummies.shape)\n",
    "pca = PCA(n_components=3)\n",
    "reduced_xy_loc = pca.fit_transform(df_xyloc_dummies)\n",
    "print(reduced_xy_loc.shape)\n",
    "\n",
    "print(reduced_xy_loc)\n",
    "\n",
    "df_all[\"xy_loc_pca_1\"] = reduced_xy_loc[:, 0]\n",
    "df_all[\"xy_loc_pca_2\"] = reduced_xy_loc[:, 1]\n",
    "df_all[\"xy_loc_pca_3\"] = reduced_xy_loc[:, 2]\n",
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xyd 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.689602Z",
     "start_time": "2020-02-20T15:53:12.842Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all_xy = df_all[[\"x\", \"y\", \"d\"]]\n",
    "print(df_all_xy.shape)\n",
    "pca = TSNE(n_components=1)\n",
    "reduced_xy = pca.fit_transform(df_all_xy)\n",
    "print(reduced_xy.shape)\n",
    "df_all[\"xy\"] = reduced_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.690946Z",
     "start_time": "2020-02-20T15:53:12.844Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_all_vd = df_all[[\"v\", \"d\"]]\n",
    "# print(df_all_vd.shape)\n",
    "# pca = PCA(n_components=1)     #加载PCA算法，设置降维后主成分数目为2\n",
    "# reduced_vd = pca.fit_transform(df_all_vd)#对样本进行降维\n",
    "# print(reduced_vd.shape)\n",
    "# df_all[\"vd\"] = reduced_vd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理时间数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.692361Z",
     "start_time": "2020-02-20T15:53:12.846Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理时间数据\n",
    "df_all = extract_dt(df_all)\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.693855Z",
     "start_time": "2020-02-20T15:53:12.847Z"
    }
   },
   "outputs": [],
   "source": [
    "# 删除重复行数据\n",
    "print(\"df_all\", df_all.shape)\n",
    "df_label = df_all.drop_duplicates('ship')\n",
    "print(\"df_label\", df_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.695167Z",
     "start_time": "2020-02-20T15:53:12.849Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看分类占比\n",
    "df_label['type'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.696779Z",
     "start_time": "2020-02-20T15:53:12.852Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 标签使用数字代替\n",
    "type_map = dict(zip(df_label['type'].unique(), np.arange(3)))\n",
    "type_map_rev = {v:k for k,v in type_map.items()}\n",
    "df_label['type'] = df_label['type'].map(type_map)\n",
    "type_map_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.698217Z",
     "start_time": "2020-02-20T15:53:12.855Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分类占比\n",
    "df_label['type'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.699934Z",
     "start_time": "2020-02-20T15:53:12.858Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造新列\n",
    "df_label = extract_feature(df_all, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.701365Z",
     "start_time": "2020-02-20T15:53:12.866Z"
    }
   },
   "outputs": [],
   "source": [
    "# 降维后合并\n",
    "reduced_xy_count_df = reduced_xy_count_df.rename(columns={\n",
    "    0: \"xy_count_pca_1\",\n",
    "    1: \"xy_count_pca_2\",\n",
    "    2: \"xy_count_pca_3\",\n",
    "})\n",
    "df_label = pd.merge(df_label, reduced_xy_count_df, on='ship', how='left')\n",
    "df_label.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.702391Z",
     "start_time": "2020-02-20T15:53:12.869Z"
    }
   },
   "outputs": [],
   "source": [
    "# 拆出暂不需要的特征\n",
    "delete_list = ['speed_time', \"record\", 'ship','type','time','diff_time','date', 'x_y_loc_area']\n",
    "features = [x for x in df_label.columns if x not in delete_list]\n",
    "target = 'type'\n",
    "\n",
    "# features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.703949Z",
     "start_time": "2020-02-20T15:53:12.870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看训练用到的列\n",
    "print(len(features), \"\\n\", '    '.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.705161Z",
     "start_time": "2020-02-20T15:53:12.873Z"
    }
   },
   "outputs": [],
   "source": [
    "train_label = df_label[df_label[\"record\"] == \"train\"]\n",
    "test_label = df_label[df_label[\"record\"] == \"test\"]\n",
    "\n",
    "train_label = train_label.drop([\"record\"], axis=1)\n",
    "test_label = test_label.drop([\"record\", \"type\"], axis=1)\n",
    "\n",
    "train_label[features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.706294Z",
     "start_time": "2020-02-20T15:53:12.876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lgbm的参数\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'learning_rate': 0.01,\n",
    "}\n",
    "\n",
    "# 交叉验证 五折\n",
    "fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 特征和标签\n",
    "X = train_label[features].copy()\n",
    "y = train_label[target]\n",
    "\n",
    "# 模型列表\n",
    "models = []\n",
    "# 预测值\n",
    "pred = np.zeros((len(test_label),3))  # onehot形式 (2000, 3)\n",
    "oof = np.zeros((len(X), 3))  # onehot形式 (7000, 3)\n",
    "\n",
    "# 循环交叉验证\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "\n",
    "    train_set = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])  # 筛选训练数据\n",
    "    val_set = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])        # 筛选验证数据\n",
    "\n",
    "    model = lgb.train(params, train_set, valid_sets=[train_set, val_set], verbose_eval=100)  # 训练模型\n",
    "    models.append(model)  # 模型列表\n",
    "    \n",
    "    # 预测标签，每个结果是 (len ,3)\n",
    "    val_pred = model.predict(X.iloc[val_idx])  \n",
    "    oof[val_idx] = val_pred\n",
    "    \n",
    "    # 原始标签\n",
    "    val_y = y.iloc[val_idx]\n",
    "    \n",
    "    # 输出最大值\n",
    "    val_pred = np.argmax(val_pred, axis=1)\n",
    "    \n",
    "    # 计算f1值\n",
    "    print(index, 'val f1(指定次数的随机验证集F1值: )', metrics.f1_score(val_y, val_pred, average='macro'))\n",
    "    \n",
    "    # 预测待提交测试集结果\n",
    "    test_pred = model.predict(test_label[features])\n",
    "    pred += test_pred/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.707395Z",
     "start_time": "2020-02-20T15:53:12.878Z"
    }
   },
   "outputs": [],
   "source": [
    "# 综合五次的交叉验证的结果评估值\n",
    "oof = np.argmax(oof, axis=1)\n",
    "print('【准确率】oof f1: ', metrics.f1_score(oof, y, average='macro'))\n",
    "\n",
    "# origin 0.8666565020816382\n",
    "# speed time 0.8556040441133175\n",
    "# speed time + xy 0.869776300826063\n",
    "# xy 0.8695008449788421\n",
    "# speed time + xyvd 0.8666262659963254\n",
    "# speed time + xyd 0.8712710026618916\n",
    "# speed time + xyv 0.8677183665397498\n",
    "# speed time + xy + vd 0.8657659692232876\n",
    "# speed time + xyd + vd 0.8683521658107259\n",
    "# xy loc 0.8755378306270695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.708947Z",
     "start_time": "2020-02-20T15:53:12.881Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(pred, axis=1)\n",
    "sub = test_label[['ship']]\n",
    "sub['pred'] = pred\n",
    "\n",
    "print(sub['pred'].value_counts(1))\n",
    "sub['pred'] = sub['pred'].map(type_map_rev)\n",
    "sub.to_csv('result.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.710405Z",
     "start_time": "2020-02-20T15:53:12.883Z"
    }
   },
   "outputs": [],
   "source": [
    "ret = []\n",
    "for index, model in enumerate(models):\n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = model.feature_name()\n",
    "    df['score'] = model.feature_importance()\n",
    "    df['fold'] = index\n",
    "    ret.append(df)\n",
    "    \n",
    "df = pd.concat(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.711861Z",
     "start_time": "2020-02-20T15:53:12.885Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.groupby('name', as_index=False)['score'].mean()\n",
    "df = df.sort_values(['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.713221Z",
     "start_time": "2020-02-20T15:53:12.887Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T15:53:21.714501Z",
     "start_time": "2020-02-20T15:53:12.888Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
